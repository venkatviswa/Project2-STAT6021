---
title: "Question2"
output: pdf_document
date: "2024-04-24"
---

**Question 2 : Does the presence of one or more of waterfront,Condition, View, Grade, Yr Built, Yr Renovated cause the price of house being sold above the median price?** 

*view - An index from 0 to 4 of how good the view of the property was: 0 = No view, 1 = Fair 2 = Average, 3 = Good, 4 = Excellent*
*condition - An index from 1 to 5 on the condition of the apartment: 1 = Poor- Worn out, 2 = Fair- Badly worn, 3 = Average, 4 = Good, 5= Very Good*
*grade - An index from 1 to 13, where 1-3 falls short of building construction and design, 7 has an average level of construction and design, and 11-13 have a high quality level of construction and design*


1.Train and Test data sets 
```{r include=FALSE}
library(tidyverse)
Data<-read.csv("kc_house_data.csv", sep=",", header=TRUE)

median_price <- median(Data$price)
Data$above_median <- Data$price > median_price
Data$waterfront<-factor(Data$waterfront)
Data$condition_boolean<-factor(as.integer(Data$condition>3))
Data$view_boolean<-factor(as.integer(Data$view>0))
Data$grade_boolean<-factor(as.integer(Data$grade>10))


set.seed(6021)
sample.data<-sample.int(nrow(Data), floor(.50*nrow(Data)), replace = F)
train<-Data[sample.data, ]
test<-Data[-sample.data, ]


options(scipen=999)

```
2. Visualizations



```{r}
summary(train$yr_built)
summary(train$yr_renovated)
```
## waterfront vs Response Variable ( Above median price)

```{r}
summary(train$waterfront)
```

Only 84 houses have waterfront 

```{r}
ggplot(train, aes(x=waterfront, fill=above_median))+
  geom_bar(position = "fill")+
  labs(x="Houses Overlooking the Waterfront", y="Proportion", 
       title="Proportion of Waterfront Houses above the median House Price")

```
Inference : We can infer that most of the houses that have waterfront are above the median price

## Condition vs Response Variable ( Above median price)

```{r}
summary_data <- train %>%
  group_by(condition) %>%
  summarize(count = n()) %>%
  mutate(percentage =  (count/ sum(count) ) * 100)
print(summary_data[, c("condition", "count", "percentage")])
```

Inference : Almost 90% of the houses seem to be in Condition 3 or 4. 

```{r}
ggplot(train, aes(x = factor(condition), fill = above_median)) +
  geom_bar(position = "fill") +
  geom_text(stat = "count", aes(label = paste0(round(..count.. / sum(..count..) * 100, 1), "%")),
            position = position_fill(vjust = 0.5), color = "black", size = 3) +  
  labs(x = "Condition", y = "Proportion", fill = "Median Price") +
    scale_y_continuous(labels = scales::percent) +
  theme_minimal()
```

Inference :  We can see that for conditions 3,4,5 the number of houses above median price is roughly equal to the houses below median price

## Grade vs Response Variable ( Above median price)

```{r}
summary_data <- train %>%
  group_by(grade) %>%
  summarize(count = n()) %>%
  mutate(percentage =  (count/ sum(count) ) * 100)
print(summary_data[, c("grade", "count", "percentage")])
```

Inference : Most of the houses are in Grade 7, 8, 9 (80% of the houses roughly)

```{r}
ggplot(train, aes(x = factor(grade), fill = above_median)) +
  geom_bar(position = "fill") +
  geom_text(stat = "count", aes(label = paste0(round(..count.. / sum(..count..) * 100, 1), "%")),
            position = position_fill(vjust = 0.5), color = "black", size = 3) +  
  labs(x = "Grade", y = "Proportion", fill = "Median Price") +
    scale_y_continuous(labels = scales::percent) +
  theme_minimal()
```
We can see that almost all the homes in Grades 10 through 13 were sold for above median price 

## View vs Response Variable ( Above median price)

```{r}
summary_data <- train %>%
  group_by(view) %>%
  summarize(count = n()) %>%
  mutate(percentage =  (count/ sum(count) ) * 100)
print(summary_data[, c("view", "count", "percentage")])
```
Almost 90% of the homes do not have a view

```{r}
ggplot(train, aes(x = factor(view), fill = above_median)) +
  geom_bar(position = "fill") +
  geom_text(stat = "count", aes(label = paste0(round(..count.. / sum(..count..) * 100, 1), "%")),
            position = position_fill(vjust = 0.5), color = "black", size = 3) +  
  labs(x = "Grade", y = "Proportion", fill = "Median Price") +
    scale_y_continuous(labels = scales::percent) +
  theme_minimal()
```
Out of the remaining 10% homes with a view , most of them are sold for above median price.

#Yr built vs response variable

```{r}

train$decade_built <- cut(train$yr_built, breaks = seq(1900, 2020, by = 10),
                   labels = paste(seq(1900, 2010, by = 10), "-", seq(1909, 2019, by = 10)))

summary_data <- train %>%
  group_by(decade_built) %>%
  summarize(count = n()) %>%
  mutate(percentage =  (count/ sum(count) ) * 100)
print(summary_data[, c("decade_built", "count", "percentage")])
```
```{r}
ggplot(train, aes(x = decade_built, fill = above_median)) +
  geom_bar(position = "fill") +
  geom_text(stat = "count", aes(label = paste0(round(..count.. / sum(..count..) * 100, 1), "%")),
            position = position_fill(vjust = 0.5), color = "black", size = 3) +  
  labs(x = "Decade built", y = "Proportion", fill = "Median Price") +
    scale_y_continuous(labels = scales::percent) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```
#Yr renovated vs response variable

```{r}

train$decade_renovated <- cut(train$yr_renovated, breaks = seq(1900, 2020, by = 10),
                   labels = paste(seq(1900, 2010, by = 10), "-", seq(1909, 2019, by = 10)))

summary_data <- train %>%
  group_by(decade_renovated) %>%
  summarize(count = n()) %>%
  mutate(percentage =  (count/ sum(count) ) * 100)
print(summary_data[, c("decade_renovated", "count", "percentage")])
```
Majority of the homes were not renovated and good chunk of homes were renovated in 1980 onwards

```{r}
train_filtered <- train %>%
  filter(!is.na(decade_renovated))

ggplot(train_filtered, aes(x = decade_renovated, fill = above_median)) +
  geom_bar(position = "fill") +
  geom_text(stat = "count", aes(label = paste0(round(..count.. / sum(..count..) * 100, 1), "%")),
            position = position_fill(vjust = 0.5), color = "black", size = 3) +  
  labs(x = "Decade Renovated", y = "Proportion", fill = "Median Price") +
    scale_y_continuous(labels = scales::percent) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

2.Use GLM and Frame the logistic Regression equation  


```{r}
result<-glm(formula=above_median~waterfront+condition_boolean+view_boolean+grade_boolean+yr_built+yr_renovated,family=binomial,data=train)
summary(result)
```
*Regression Equation is as follows*
$$log(\frac{\hat\pi}{1+\hat\pi})=-11.363+0.5762\ waterfront1+0.1675\ condition\_boolean1+16.055 grade\_boolean1+1.563\ view\_boolean+0.005\ yr\_built+0.0004\ yr\_renovated$$
Inference : 

*coefficient for waterfront is 0.5762*
  * Estimated log odds of higher than median price for a property with waterfront is 0.5762 more than property without waterfront while controlling for condition, grade , view , year built and year renovated
  * Estimated  odds of higher than median price for a property with waterfront is exp(0.5762)=1.7792 times the odds of property without waterfront while controlling for condition, grade , view , year built and year renovated
  * Assessing the coefficient for Waterfront using Wald test :
    - $H_{0}$ is $\beta_{1}$=0. $H_{a}$ is $\beta_{1}\neq\ 0$
    - Test statistic is Z = $\frac{\hat\beta_{1}-0}{se(\hat\beta_{1})}$ = $\frac{0.2296}{0.4139}=0.5547$
    - P value is 0.5791 which is more than test statistic and also much more than 0.05
    - we accept the null hypotheses and can drop the waterfront from the logistic regression model
  

*coefficient for condition is 0.1756*
  * Estimated log odds of higher than median price for a property in good condition is 0.1756 more than property in not good condition while controlling for waterfront, grade , view , year built and year renovated
  * Estimated  odds of higher than median price for a property in good condition is exp(0.2295)=1.1919 times the odds of property not in good condition while controlling for waterfront, grade , view , year built and year renovated

*coefficient for grade is 16.2102 and standard error is 141.4962*
  * since the standard error is very high the predictor is not reliable and recommend to drop the predictor*

*coefficient for view is 1.9211*
  *. Estimated log odds of higher than median price for a property with good view is 1.9211 more than property not having a good view while controlling for waterfront, grade , condition , year built and year renovated
  * Estimated  odds of higher than median price for a property in good view is exp(1.9211)=6.828 times the odds of property with a good view while controlling for waterfront, grade , condition , year built and year renovated
  
*coeeficient for year built is 0.0049*
  *. for every year thats added to the year built ( as in newer property) Estimated log odds of higher than median price for a property is 0.0049 more  while controlling for waterfront, grade , condition , view and year renovated
  * for every year thats added to the year built ( as in newer property) Estimated odds is exp(0.0049)=1.005 more  while controlling for waterfront, grade , condition , year built and year renovated
  
*coeeficient for year renovated is 0.0004*
  *. for every year thats added to the year renovated ( as in newer property) Estimated log odds of higher than median price for a property is 0.0049 more  while controlling for waterfront, grade , view ,condition and year built 
  * for every year thats added to the year renovated ( as in newer property) Estimated odds is exp(0.0049)=1.004 more  while controlling for waterfront, grade , condition , view and year built 

**Dropping  grade we create a reduced model next**

```{r}
reduced<-glm(formula=above_median~waterfront+condition_boolean+view_boolean+yr_built+yr_renovated,family=binomial,data=train)
summary(reduced)
```
*Updated Regression Equation is as follows*
$$log(\frac{\hat\pi}{1+\hat\pi})=-13.15+0.651I_{1}+0.159I_{2}+1.653I_{3}+0.006x_{1}+0.0004x_{2}$$
Checking for interactions :

```{r}
reduced.int<-glm(formula=above_median~waterfront*yr_built+condition_boolean*yr_built+view_boolean*yr_built+yr_built*yr_renovated,
                 family=binomial,data=train)
summary(reduced.int)
```

Inference : there appears to be interaction between Yr_built and condition and Yr_built and View

```{r}
anova(reduced,reduced.int)
```


5. Determine usefulness of model using Likelihood Ratio test 
 $H_{0}$ is $\beta_{1}$=$\beta_{2}$=$\beta_{3}$=$\beta_{4}$=0. $H_{a}$ is atleast one coefficient is non zero

$$\Delta G^{2}=D(R)-D(F) = 14979-14550=429 $$
P value is 1- pchisq(429,4)= 0
Critical value is qchisq(0.95,4) = 9.48995
We reject the null hypothesis and support our four predictor over the intercept-only model.

6. Create confusion matrix 

```{r}
##predicted survival rate for test data based on training data
preds<-predict(reduced,newdata=test, type="response")
##add predicted probabilities and classification based on threshold
test.new<-data.frame(test,preds,preds>0.5)
##disply actual response, predicted prob, and classification based on threshold
#head(test.new[,c(22,23,24,25,26,27)], )
table(test$above_median, preds>0.5)
```

Error rate is (1512+3252)/10807 = 0.44
Accuracy is (3889+2154)/10807 = 0.56
FPR is 1512/(1512+3889)=0.2799
FNR is 3252/(3252+2154)=0.6015
TPR is 2154/(3252+2154)=0.3984
TNR is 3889/(1512+3889)=0.72

7. ROC Curve
```{r}
library(ROCR)
##produce the numbers associated with classification table
rates<-ROCR::prediction(preds, test$above_median)
##store the true positive and false positive rates
roc_result<-ROCR::performance(rates,measure="tpr", x.measure="fpr")
##plot ROC curve and overlay the diagonal line for random guessing
plot(roc_result, main="ROC Curve for Reduced Model")
lines(x = c(0,1), y = c(0,1), col="red")
points(x=0.2799, y=0.3984, col="blue", pch=16)
```

ROC above is above the diagonal so it does better than random guessing

8. AUC 

```{r}
auc<-performance(rates, measure = "auc")
auc@y.values
```

AUC is around 0.579 which is greater than 0.5 so it does better than random guessing 

